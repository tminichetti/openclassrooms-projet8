# CLAUDE.MD - Projet 8 OpenClassrooms

## Vue d'ensemble du projet

**Nom du projet**: Syst√®me de segmentation d'images pour v√©hicules autonomes
**Organisation**: Future Vision Transport
**Objectif**: Concevoir un mod√®le de segmentation d'images pour syst√®me embarqu√© de vision par ordinateur

## Contexte m√©tier

Ce projet s'inscrit dans le d√©veloppement d'un syst√®me embarqu√© de vision par ordinateur pour v√©hicules autonomes. Le syst√®me complet est compos√© de 4 modules :

1. **Acquisition des images** en temps r√©el
2. **Traitement des images** (Franck)
3. **Segmentation des images** ‚Üê VOTRE R√îLE
4. **Syst√®me de d√©cision** (Laura)

### Contraintes des parties prenantes

**Franck (Traitement d'images)**:
- Dataset: Cityscapes (images de cam√©ras embarqu√©es)
- Lien: disponible dans les fichiers MISSION.md
- Utiliser uniquement les **8 cat√©gories principales** (pas les 32 sous-cat√©gories)

**Laura (Syst√®me de d√©cision)**:
- Besoin d'une **API simple**
- Entr√©e: image
- Sortie: segmentation (mask pr√©dit)

## Structure du projet

```
.
‚îú‚îÄ‚îÄ data/                      # Donn√©es du projet
‚îÇ   ‚îú‚îÄ‚îÄ config.json           # Configuration des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ gtFine/               # Ground truth (annotations)
‚îÇ   ‚îú‚îÄ‚îÄ leftImg8bit/          # Images sources
‚îÇ   ‚îú‚îÄ‚îÄ train_paths.csv       # Chemins images d'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ val_paths.csv         # Chemins images de validation
‚îÇ   ‚îî‚îÄ‚îÄ test_paths.csv        # Chemins images de test
‚îú‚îÄ‚îÄ notebooks/                 # Pipeline de d√©veloppement
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploration.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_data_preparation.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_model_architecture.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 04_training.ipynb
‚îú‚îÄ‚îÄ src/                       # Code source
‚îÇ   ‚îú‚îÄ‚îÄ models.py             # Architecture des mod√®les
‚îÇ   ‚îî‚îÄ‚îÄ utils.py              # Fonctions utilitaires
‚îú‚îÄ‚îÄ logs/                      # Logs d'entra√Ænement
‚îú‚îÄ‚îÄ requirements.txt           # D√©pendances Python
‚îî‚îÄ‚îÄ requirements-macbook.txt   # D√©pendances macOS sp√©cifiques
```

## Technologies utilis√©es

- **Framework ML**: Keras (standard de l'√©quipe R&D)
- **Dataset**: Cityscapes (8 cat√©gories principales)
- **API**: Flask ou FastAPI (√† d√©ployer sur Cloud)
- **Application web**: Flask ou Streamlit (pour pr√©sentation r√©sultats)
- **D√©ploiement**: Azure, Heroku, PythonAnywhere ou autre solution Cloud

## Livrables attendus

### 1. Pipeline complet dans notebooks ‚úì
- Scripts permettant l'ex√©cution du pipeline complet
- D√©monstration du caract√®re "industrialisable"
- Focus sur le g√©n√©rateur de donn√©es

### 2. API de pr√©diction (√† d√©ployer)
- **Framework**: Flask ou FastAPI
- **Entr√©e**: Image
- **Sortie**: Mask pr√©dit (segments identifi√©s)
- **D√©ploiement**: Cloud (Azure/Heroku/PythonAnywhere)
- **Utilisateur final**: Laura (syst√®me de d√©cision)

### 3. Application web de pr√©sentation (√† d√©ployer)
- **Framework**: Flask ou Streamlit
- **Fonctionnalit√©s**:
  - Affichage de la liste des IDs d'images disponibles
  - S√©lection d'une image par ID
  - Lancement de la pr√©diction via appel API
  - Affichage: image r√©elle + mask r√©el + mask pr√©dit
- **D√©ploiement**: Cloud (Azure/Heroku/PythonAnywhere)

### 4. Note technique (~10 pages)
- Pr√©sentation des diff√©rentes approches
- Synth√®se de l'√©tat de l'art
- Pr√©sentation d√©taill√©e du mod√®le et architecture retenue
- Synth√®se des r√©sultats (incluant gains avec augmentation de donn√©es)
- Conclusion et pistes d'am√©lioration

### 5. Support de pr√©sentation (max 30 slides)
- D√©marche m√©thodologique
- Pr√©sentation des r√©sultats pour Laura

## Milestones du projet

### ‚úÖ Milestone 1 : Conception des mod√®les
**Livrable** : Notebook partie conception des mod√®les
- ‚úÖ Utiliser images `gtFine_labelIds` (34 classes ‚Üí 8 cat√©gories)
- ‚úÖ Tester mod√®le simple : Unet mini
- ‚úÖ Tester mod√®le pr√©-entra√Æn√© : VGG16 Unet (Transfer Learning)
- ‚úÖ Tester diff√©rentes loss : Dice_loss, total_loss, balanced_cross_entropy
- ‚úÖ M√©triques : IoU (Jaccard) et Dice_coeff
- ‚úÖ Utiliser `tensorflow.keras.xxx` pour compatibilit√©

### ‚úÖ Milestone 2 : G√©n√©rateur de donn√©es
**Livrable** : Notebook avec classe Sequence + augmentation
- ‚úÖ Classe Python de type `Sequence` pour g√©n√©rateur
- ‚úÖ Redimensionnement correct (X ‚Üí entr√©e mod√®le, y ‚Üí sortie mod√®le)
- ‚úÖ Augmentation de donn√©es int√©gr√©e (albumentations ou imgaug)
- ‚úÖ Traitement sur plusieurs c≈ìurs de calcul
- ‚úÖ Script enti√®rement automatis√©

### üîÑ Milestone 3 : Entra√Ænement et comparaison
**Livrable** : Notebook simulations + tableau r√©capitulatif
- üîÑ Entra√Ænement des mod√®les (local ou Azure ML Studio)
- üîÑ Utiliser EarlyStopping (arr√™t apr√®s N epochs sans am√©lioration)
- üîÑ Utiliser ModelCheckpoint (sauvegarde meilleur mod√®le)
- üîÑ Tableau comparatif des mod√®les (performances + temps)
- üîÑ Synth√®se gains avec augmentation de donn√©es

### ‚úÖ Milestone 4 : Cr√©ation de l'API
**Livrable** : Code Python API Flask/FastAPI
- ‚úÖ API Flask cr√©√©e dans `/api`
- ‚úÖ Endpoints : `/`, `/health`, `/predict`
- ‚úÖ Entr√©e : image | Sortie : mask pr√©dit
- ‚úÖ Dockerfile pour d√©ploiement Heroku

### ‚úÖ Milestone 5 : Application Web
**Livrable** : Application Web d'interaction
- ‚úÖ Application Streamlit cr√©√©e dans `/streamlit`
- ‚úÖ Upload d'images
- ‚úÖ Appel API de pr√©diction
- ‚úÖ Affichage : image r√©elle + mask pr√©dit + overlay
- ‚úÖ Distribution des classes
- ‚úÖ Pr√™te pour d√©ploiement Streamlit Cloud

### ‚è≥ Milestone 6 : Mise en production
**Livrable** : D√©ploiements Cloud
- [ ] API d√©ploy√©e sur Heroku (avec mod√®le)
- [ ] Application Streamlit d√©ploy√©e sur Streamlit Cloud
- [ ] URLs accessibles et fonctionnelles
- [ ] Tests de bout en bout

## √âtat actuel du projet

### Notebooks d√©velopp√©s
- ‚úÖ `01_exploration.ipynb` - Exploration des donn√©es
- ‚úÖ `02_data_preparation.ipynb` - Pr√©paration et pr√©traitement
- ‚úÖ `03_model_architecture.ipynb` - Conception architecture
- üîÑ `04_training.ipynb` - Entra√Ænement (structure pr√™te, √† ex√©cuter)
- ‚úÖ `05_evaluation.ipynb` - √âvaluation et comparaison des mod√®les

### Code source
- ‚úÖ `src/models.py` - Architectures de mod√®les
- ‚úÖ `src/utils.py` - Fonctions utilitaires
- ‚úÖ `api/app.py` - API Flask de pr√©diction
- ‚úÖ `streamlit/app.py` - Application Web Streamlit

### Infrastructure d√©ploiement
- ‚úÖ `api/` - Dossier API avec Dockerfile Heroku
- ‚úÖ `streamlit/` - Dossier Streamlit Cloud ready
- ‚úÖ Documentation compl√®te (READMEs)

### Donn√©es
- ‚úÖ Dataset Cityscapes t√©l√©charg√© et organis√©
- ‚úÖ Fichiers CSV de chemins g√©n√©r√©s (train/val/test)
- ‚úÖ Configuration (config.json)

### √Ä faire (priorit√©)
- [x] Analyser la conformit√© des notebooks avec les milestones
- [x] Cr√©er script d'entra√Ænement Python standalone (`train.py`)
- [x] Cr√©er script de comparaison des mod√®les (`compare_models.py`)
- [x] Documenter le processus d'entra√Ænement (`GUIDE_ENTRAINEMENT.md`)
- [ ] **Ex√©cuter les entra√Ænements** (Milestone 3 - CRITIQUE) :
  - [ ] U-Net sans augmentation (baseline)
  - [ ] U-Net avec augmentation
  - [ ] VGG16 avec augmentation (recommand√©)
- [ ] G√©n√©rer le tableau comparatif avec `compare_models.py`
- [ ] Copier le meilleur mod√®le ‚Üí `api/model/segmentation_model.h5`
- [ ] D√©ployer l'API sur Heroku (Milestone 6)
- [ ] D√©ployer l'application sur Streamlit Cloud (Milestone 6)
- [ ] Tester le syst√®me complet bout-en-bout
- [ ] R√©diger la note technique (~10 pages)
- [ ] Pr√©parer le support de pr√©sentation (max 30 slides)

## Commandes utiles

### Environnement
```bash
# Activer l'environnement virtuel
source .venv/bin/activate

# Installer les d√©pendances
pip install -r requirements.txt
# ou pour macOS
pip install -r requirements-macbook.txt
```

### Jupyter
```bash
# Lancer Jupyter
jupyter notebook
```

### Git
```bash
# Voir le statut
git status

# √âtat actuel: fichiers modifi√©s
# - notebooks/01_exploration.ipynb
# - notebooks/02_data_preparation.ipynb
# - notebooks/03_model_architecture.ipynb
```

## Crit√®res d'√©valuation (points cl√©s)

### 1. Strat√©gie d'√©laboration du mod√®le
- ‚úÖ D√©finir strat√©gie (mod√®le simple vs pr√©-entra√Æn√©)
- ‚úÖ Identifier les cibles (8 cat√©gories Cityscapes)
- ‚úÖ S√©paration train/val/test (pas de fuite d'information)
- ‚úÖ Tester plusieurs mod√®les (simple ‚Üí complexe)
  - Exemple : Unet mini ‚Üí VGG16 Unet
- ‚úÖ Transfer Learning impl√©ment√©

### 2. √âvaluation de la performance
- ‚úÖ **M√©trique principale** : IoU ou Dice_coef (adapt√© √† la segmentation)
- ‚úÖ Expliciter le choix de la m√©trique
- ‚úÖ Mod√®le de r√©f√©rence pour comparaison
- üîÑ **Indicateurs compl√©mentaires** : temps d'entra√Ænement, m√©moire
- üîÑ Optimisation hyperparam√®tres (Loss, Batch Size, Epochs)
- üîÑ **Tableau comparatif** des mod√®les
- ‚è≥ **API d√©ploy√©e** : entr√©e image ‚Üí sortie mask
- ‚úÖ API ind√©pendante de l'application web
- ‚úÖ Pipeline d√©ploiement continu (Git/GitHub + Cloud)

### 3. Augmentation de donn√©es
- ‚úÖ Plusieurs techniques test√©es (rotation, √©chelle, bruit, etc.)
- üîÑ **Synth√®se comparative** des gains de performance
- üîÑ Impact sur l'overfitting document√©

### 4. Manipulation de donn√©es volumineuses
- ‚úÖ **G√©n√©rateur de donn√©es** d√©velopp√© (classe Sequence)
- ‚úÖ Traitement sur plusieurs c≈ìurs de calcul
- ‚úÖ Script enti√®rement automatis√©

## Points d'attention

### Contraintes techniques
1. **Framework obligatoire** : Keras (standard √©quipe)
2. **Images target** : Utiliser `gtFine_labelIds` (34 classes ‚Üí 8 cat√©gories)
3. **8 cat√©gories seulement** : Ne pas utiliser les 32 sous-cat√©gories
4. **Compatibilit√©** : Tout en `tensorflow.keras.xxx` pour √©viter les conflits
5. **Redimensionnement** :
   - Dimension X = dimension d'entr√©e du mod√®le
   - Dimension y (mask) = dimension de sortie du mod√®le
6. **Simplicit√© API** : Laura a besoin d'une interface simple

### Crit√®res de qualit√©
- **Industrialisable** : Code production-ready
- **G√©n√©rateur de donn√©es** : Optimis√© pour l'entra√Ænement (multicore)
- **API robuste** : Gestion des erreurs et validation
- **Documentation** : Code bien document√©
- **Callbacks** : EarlyStopping + ModelCheckpoint obligatoires

### Augmentation de donn√©es
- Approches d'augmentation doivent √™tre test√©es
- Gains √† documenter dans la note technique
- Utiliser `albumentations` ou `imgaug` recommand√©

## Workflow de d√©ploiement

### Phase 1 : Entra√Ænement (en cours)
```bash
# 1. Finaliser l'entra√Ænement dans le notebook 04_training.ipynb
# 2. S'assurer d'avoir EarlyStopping et ModelCheckpoint
# 3. Sauvegarder le meilleur mod√®le
model.save('best_model.h5')
```

### Phase 2 : Pr√©paration API
```bash
# 1. Copier le mod√®le dans le dossier API
cp best_model.h5 api/model/segmentation_model.h5

# 2. Tester l'API localement
cd api
pip install -r requirements.txt
python app.py

# 3. Tester avec le script de test
python test_api.py http://localhost:5000 chemin/vers/image.jpg
```

### Phase 3 : D√©ploiement API sur Heroku
```bash
cd api
heroku login
heroku create nom-api-segmentation
heroku stack:set container
git init
git add .
git commit -m "Deploy API"
git push heroku main

# Noter l'URL : https://nom-api-segmentation.herokuapp.com
```

### Phase 4 : D√©ploiement Streamlit Cloud
```bash
# 1. Pousser le code sur GitHub
git add streamlit/
git commit -m "Add Streamlit app"
git push origin main

# 2. Aller sur https://share.streamlit.io/
# 3. Cr√©er une nouvelle app pointant vers streamlit/app.py
# 4. Configurer les secrets avec l'URL de l'API Heroku
# 5. D√©ployer !
```

### Phase 5 : Tests bout-en-bout
```bash
# 1. Tester l'API sur Heroku
curl https://nom-api-segmentation.herokuapp.com/health

# 2. Uploader une image dans Streamlit
# 3. V√©rifier que la pr√©diction fonctionne
# 4. Documenter les URLs dans la note technique
```

## Ressources

### Dataset et documentation
- **Dataset** : Cityscapes (voir MISSION.md pour liens)
- **Documentation projet** : MISSION.md, LIVRABLES.md, MILESTONES.md
- **Cat√©gories principales** : 8 classes de segmentation s√©mantique

### Mod√®les recommand√©s
- **Mod√®le simple** : Unet mini (baseline)
- **Mod√®le pr√©-entra√Æn√©** : VGG16 Unet (Transfer Learning)
- **Autres encodeurs** : ResNet, EfficientNet (optionnel)

### Loss functions √† tester
- `Dice_loss` : Adapt√© √† la segmentation
- `total_loss` : Combinaison de plusieurs loss
- `balanced_cross_entropy` : Pour classes d√©s√©quilibr√©es

### M√©triques d'√©valuation
- **IoU (Jaccard)** : Intersection over Union (m√©trique principale)
- **Dice coefficient** : Similaire √† IoU, souvent utilis√© en segmentation
- **Temps d'entra√Ænement** : Pour comparer l'efficacit√©

### Librairies d'augmentation
- `albumentations` : Recommand√©, performant
- `imgaug` : Alternative valide

## Notes de d√©veloppement

### Choix d'architecture
- √Ä documenter apr√®s exp√©rimentation dans notebooks

### R√©sultats d'entra√Ænement
- M√©triques √† ajouter apr√®s entra√Ænement complet
- Comparaison des diff√©rentes approches

### Optimisations
- G√©n√©rateur de donn√©es pour gestion m√©moire
- Augmentation de donn√©es pour am√©liorer performance

## R√©capitulatif de l'avancement

```
Progression globale du projet : ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 60%

Milestones:
‚úÖ M1 - Conception mod√®les          [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
‚úÖ M2 - G√©n√©rateur de donn√©es       [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
üîÑ M3 - Entra√Ænement                [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]  60%
‚úÖ M4 - API Flask                   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
‚úÖ M5 - Application Web             [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
‚è≥ M6 - D√©ploiement Cloud           [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]   0%

Livrables:
‚úÖ Notebooks (01-03)                [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
üîÑ Notebook 04 (training)           [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]  60%
‚úÖ API Flask + Dockerfile           [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
‚úÖ App Streamlit                    [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
‚è≥ Note technique                   [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]   0%
‚è≥ Support pr√©sentation             [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]   0%
```

### Prochaines √©tapes prioritaires

1. **Finaliser l'entra√Ænement** (Milestone 3)
   - Compl√©ter notebook `04_training.ipynb`
   - G√©n√©rer tableau comparatif des mod√®les
   - Documenter gains avec augmentation de donn√©es

2. **Sauvegarder le mod√®le**
   - Exporter le meilleur mod√®le ‚Üí `api/model/segmentation_model.h5`

3. **D√©ployer sur le Cloud** (Milestone 6)
   - API sur Heroku
   - Streamlit sur Streamlit Cloud
   - Tests bout-en-bout

4. **R√©diger les livrables finaux**
   - Note technique (~10 pages)
   - Support de pr√©sentation (max 30 slides)

---

**Derni√®re mise √† jour** : 2026-01-30
**Statut** : En d√©veloppement - Phase d'entra√Ænement (Milestone 3)
**Infrastructure** : Pr√™te pour d√©ploiement (API + Streamlit)
