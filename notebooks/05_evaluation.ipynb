{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# √âvaluation et Comparaison des Mod√®les\n",
    "\n",
    "Ce notebook r√©alise l'√©valuation compl√®te et la comparaison des mod√®les entra√Æn√©s.\n",
    "\n",
    "## Objectifs\n",
    "- Charger et comparer tous les mod√®les entra√Æn√©s\n",
    "- Analyser l'impact de la data augmentation\n",
    "- Comparer les architectures (U-Net vs VGG16)\n",
    "- G√©n√©rer un tableau comparatif pour la note technique\n",
    "- √âvaluer sur le test set\n",
    "- Visualiser des pr√©dictions qualitatives\n",
    "- Identifier le meilleur mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Configuration affichage\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "sns.set_palette('husl')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins\n",
    "LOGS_DIR = Path('../logs')\n",
    "MODELS_DIR = Path('../models')\n",
    "DATA_DIR = Path('../data')\n",
    "\n",
    "# Charger config\n",
    "with open(DATA_DIR / 'config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "IMG_HEIGHT = config['img_height']\n",
    "IMG_WIDTH = config['img_width']\n",
    "N_CLASSES = config['n_classes']\n",
    "\n",
    "print(f\"Configuration: {IMG_WIDTH}x{IMG_HEIGHT}, {N_CLASSES} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des R√©sultats d'Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger tous les r√©sultats\n",
    "results_file = LOGS_DIR / 'all_results.csv'\n",
    "\n",
    "if not results_file.exists():\n",
    "    print(\"‚ùå Aucun r√©sultat trouv√© !\")\n",
    "    print(\"\\nVous devez d'abord entra√Æner les mod√®les avec:\")\n",
    "    print(\"  python train.py --model unet --no-augmentation --epochs 30\")\n",
    "    print(\"  python train.py --model unet --augmentation --epochs 30\")\n",
    "    print(\"  python train.py --model vgg16 --augmentation --epochs 30\")\n",
    "else:\n",
    "    df_results = pd.read_csv(results_file)\n",
    "    print(f\"‚úÖ {len(df_results)} entra√Ænement(s) trouv√©(s)\\n\")\n",
    "    display(df_results[['experiment', 'model', 'augmentation', 'val_dice', 'val_miou', \n",
    "                        'val_accuracy', 'training_time_minutes', 'epochs_trained']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tableau Comparatif des Mod√®les\n",
    "\n",
    "### 3.1 Vue d'ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un tableau format√© pour la note technique\n",
    "df_table = df_results[['model', 'augmentation', 'val_dice', 'val_miou', \n",
    "                        'val_accuracy', 'training_time_minutes', 'epochs_trained']].copy()\n",
    "\n",
    "df_table.columns = ['Mod√®le', 'Augmentation', 'Dice', 'mIoU', 'Accuracy', 'Temps (min)', 'Epochs']\n",
    "df_table['Mod√®le'] = df_table['Mod√®le'].str.upper()\n",
    "df_table['Augmentation'] = df_table['Augmentation'].map({True: 'Oui', False: 'Non'})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLEAU COMPARATIF DES MOD√àLES DE SEGMENTATION\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "display(df_table.style.format({\n",
    "    'Dice': '{:.4f}',\n",
    "    'mIoU': '{:.4f}',\n",
    "    'Accuracy': '{:.4f}',\n",
    "    'Temps (min)': '{:.1f}'\n",
    "}).background_gradient(subset=['Dice', 'mIoU', 'Accuracy'], cmap='RdYlGn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Tableau pour export (LaTeX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporter en LaTeX pour la note technique\n",
    "latex_table = df_table.to_latex(\n",
    "    index=False, \n",
    "    float_format=\"%.4f\",\n",
    "    caption=\"Comparaison des performances des mod√®les de segmentation s√©mantique\",\n",
    "    label=\"tab:model_comparison\"\n",
    ")\n",
    "\n",
    "# Sauvegarder\n",
    "with open(LOGS_DIR / 'comparison_table.tex', 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(\"‚úÖ Tableau LaTeX sauvegard√©: logs/comparison_table.tex\\n\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualisations Comparatives\n",
    "\n",
    "### 4.1 Graphiques de comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©parer les donn√©es pour visualisation\n",
    "df_plot = df_results.copy()\n",
    "df_plot['label'] = df_plot.apply(\n",
    "    lambda x: f\"{x['model'].upper()}\\n{'avec aug' if x['augmentation'] else 'sans aug'}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Couleurs selon augmentation\n",
    "colors = ['#2ecc71' if aug else '#e74c3c' for aug in df_plot['augmentation']]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Dice Coefficient\n",
    "axes[0, 0].bar(range(len(df_plot)), df_plot['val_dice'], color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[0, 0].set_xticks(range(len(df_plot)))\n",
    "axes[0, 0].set_xticklabels(df_plot['label'], fontsize=9)\n",
    "axes[0, 0].set_title('Dice Coefficient', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Dice')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0, 0].set_ylim([0, 1])\n",
    "\n",
    "# Ajouter valeurs sur les barres\n",
    "for i, v in enumerate(df_plot['val_dice']):\n",
    "    axes[0, 0].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Mean IoU\n",
    "axes[0, 1].bar(range(len(df_plot)), df_plot['val_miou'], color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[0, 1].set_xticks(range(len(df_plot)))\n",
    "axes[0, 1].set_xticklabels(df_plot['label'], fontsize=9)\n",
    "axes[0, 1].set_title('Mean IoU (Jaccard)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('mIoU')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "axes[0, 1].set_ylim([0, 1])\n",
    "\n",
    "for i, v in enumerate(df_plot['val_miou']):\n",
    "    axes[0, 1].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Accuracy\n",
    "axes[1, 0].bar(range(len(df_plot)), df_plot['val_accuracy'], color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[1, 0].set_xticks(range(len(df_plot)))\n",
    "axes[1, 0].set_xticklabels(df_plot['label'], fontsize=9)\n",
    "axes[1, 0].set_title('Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 0].set_ylim([0, 1])\n",
    "\n",
    "for i, v in enumerate(df_plot['val_accuracy']):\n",
    "    axes[1, 0].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Temps d'entra√Ænement\n",
    "axes[1, 1].bar(range(len(df_plot)), df_plot['training_time_minutes'], color='#3498db', edgecolor='black', linewidth=1.5)\n",
    "axes[1, 1].set_xticks(range(len(df_plot)))\n",
    "axes[1, 1].set_xticklabels(df_plot['label'], fontsize=9)\n",
    "axes[1, 1].set_title('Temps d\\'entra√Ænement', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Minutes')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, v in enumerate(df_plot['training_time_minutes']):\n",
    "    axes[1, 1].text(i, v + (df_plot['training_time_minutes'].max()*0.02), \n",
    "                    f'{v:.0f}min', ha='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "# L√©gende\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#2ecc71', edgecolor='black', label='Avec augmentation'),\n",
    "    Patch(facecolor='#e74c3c', edgecolor='black', label='Sans augmentation')\n",
    "]\n",
    "fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.98), ncol=2, fontsize=11)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(LOGS_DIR / 'comparison_metrics.png', dpi=150, bbox_inches='tight')\n",
    "print(\"‚úÖ Graphique sauvegard√©: logs/comparison_metrics.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Comparaison directe Dice vs mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for i, row in df_results.iterrows():\n",
    "    marker = 'o' if row['augmentation'] else 's'\n",
    "    color = '#2ecc71' if row['augmentation'] else '#e74c3c'\n",
    "    label = f\"{row['model'].upper()} ({'aug' if row['augmentation'] else 'no-aug'})\"\n",
    "    \n",
    "    ax.scatter(row['val_dice'], row['val_miou'], s=300, marker=marker, \n",
    "               color=color, edgecolor='black', linewidth=2, label=label, alpha=0.7)\n",
    "    \n",
    "    # Annoter\n",
    "    ax.annotate(row['model'].upper(), \n",
    "                (row['val_dice'], row['val_miou']),\n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Dice Coefficient', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Mean IoU', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Comparaison Dice vs mIoU', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "\n",
    "# Ligne diagonale de r√©f√©rence\n",
    "lims = [0, 1]\n",
    "ax.plot(lims, lims, 'k--', alpha=0.3, linewidth=2, label='Dice = mIoU')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(LOGS_DIR / 'dice_vs_miou.png', dpi=150, bbox_inches='tight')\n",
    "print(\"‚úÖ Graphique sauvegard√©: logs/dice_vs_miou.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse de l'Impact de l'Augmentation\n",
    "\n",
    "### 5.1 Calcul des gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSE DE L'IMPACT DE L'AUGMENTATION DE DONN√âES\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "gains = []\n",
    "\n",
    "for model_name in df_results['model'].unique():\n",
    "    model_df = df_results[df_results['model'] == model_name]\n",
    "    \n",
    "    with_aug = model_df[model_df['augmentation'] == True]\n",
    "    without_aug = model_df[model_df['augmentation'] == False]\n",
    "    \n",
    "    if len(with_aug) == 0 or len(without_aug) == 0:\n",
    "        print(f\"‚ö†Ô∏è  {model_name.upper()}: Comparaison impossible (manque avec/sans augmentation)\\n\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"üìä Mod√®le: {model_name.upper()}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    metrics = ['val_dice', 'val_miou', 'val_accuracy']\n",
    "    metric_names = ['Dice Coefficient', 'Mean IoU', 'Accuracy']\n",
    "    \n",
    "    for metric, name in zip(metrics, metric_names):\n",
    "        val_with = with_aug[metric].values[0]\n",
    "        val_without = without_aug[metric].values[0]\n",
    "        gain_abs = val_with - val_without\n",
    "        gain_pct = (gain_abs / val_without) * 100\n",
    "        \n",
    "        print(f\"  {name:20} | Sans aug: {val_without:.4f} | Avec aug: {val_with:.4f} | \"\n",
    "              f\"Gain: {gain_abs:+.4f} ({gain_pct:+.2f}%)\")\n",
    "        \n",
    "        gains.append({\n",
    "            'model': model_name,\n",
    "            'metric': name,\n",
    "            'without_aug': val_without,\n",
    "            'with_aug': val_with,\n",
    "            'gain_abs': gain_abs,\n",
    "            'gain_pct': gain_pct\n",
    "        })\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Cr√©er DataFrame des gains\n",
    "df_gains = pd.DataFrame(gains)\n",
    "if len(df_gains) > 0:\n",
    "    print(\"\\nüìà R√©sum√© des gains moyens:\")\n",
    "    print(\"-\" * 80)\n",
    "    summary = df_gains.groupby('metric')[['gain_abs', 'gain_pct']].mean()\n",
    "    print(summary.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Visualisation des gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_gains) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Gains absolus\n",
    "    pivot_abs = df_gains.pivot(index='metric', columns='model', values='gain_abs')\n",
    "    pivot_abs.plot(kind='bar', ax=axes[0], color=['#3498db', '#e74c3c'], edgecolor='black', linewidth=1.5)\n",
    "    axes[0].set_title('Gains Absolus avec Augmentation', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Gain')\n",
    "    axes[0].set_xlabel('')\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    axes[0].legend(title='Mod√®le')\n",
    "    axes[0].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    \n",
    "    # Gains en pourcentage\n",
    "    pivot_pct = df_gains.pivot(index='metric', columns='model', values='gain_pct')\n",
    "    pivot_pct.plot(kind='bar', ax=axes[1], color=['#3498db', '#e74c3c'], edgecolor='black', linewidth=1.5)\n",
    "    axes[1].set_title('Gains Relatifs avec Augmentation', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Gain (%)')\n",
    "    axes[1].set_xlabel('')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    axes[1].legend(title='Mod√®le')\n",
    "    axes[1].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(LOGS_DIR / 'augmentation_impact.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"‚úÖ Graphique sauvegard√©: logs/augmentation_impact.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Identification du Meilleur Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lectionner selon Dice (m√©trique principale pour segmentation)\n",
    "best_idx = df_results['val_dice'].idxmax()\n",
    "best_model = df_results.loc[best_idx]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ MEILLEUR MOD√àLE IDENTIFI√â\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(f\"Mod√®le: {best_model['model'].upper()}\")\n",
    "print(f\"Augmentation: {'Oui' if best_model['augmentation'] else 'Non'}\")\n",
    "print(f\"\\nüìä Performances:\")\n",
    "print(f\"  - Dice Coefficient: {best_model['val_dice']:.4f}\")\n",
    "print(f\"  - Mean IoU: {best_model['val_miou']:.4f}\")\n",
    "print(f\"  - Accuracy: {best_model['val_accuracy']:.4f}\")\n",
    "print(f\"\\n‚è±Ô∏è  Entra√Ænement:\")\n",
    "print(f\"  - Temps: {best_model['training_time_minutes']:.1f} minutes\")\n",
    "print(f\"  - Epochs: {best_model['epochs_trained']}\")\n",
    "print(f\"\\nüíæ Fichier mod√®le:\")\n",
    "print(f\"  {best_model['model_path']}\")\n",
    "print(f\"\\nüìù Exp√©rience:\")\n",
    "print(f\"  {best_model['experiment']}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyse des Courbes d'Apprentissage\n",
    "\n",
    "### 7.1 Comparaison des courbes de loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "for _, row in df_results.iterrows():\n",
    "    # Charger l'historique\n",
    "    exp_dir = LOGS_DIR / row['experiment']\n",
    "    history_file = exp_dir / 'history.csv'\n",
    "    \n",
    "    if not history_file.exists():\n",
    "        continue\n",
    "    \n",
    "    history = pd.read_csv(history_file)\n",
    "    label = f\"{row['model'].upper()} ({'aug' if row['augmentation'] else 'no-aug'})\"\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history['val_loss'], label=label, linewidth=2)\n",
    "    \n",
    "    # Dice\n",
    "    axes[0, 1].plot(history['val_dice_coefficient'], label=label, linewidth=2)\n",
    "    \n",
    "    # mIoU\n",
    "    axes[1, 0].plot(history['val_mean_iou'], label=label, linewidth=2)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1, 1].plot(history['val_accuracy'], label=label, linewidth=2)\n",
    "\n",
    "axes[0, 0].set_title('Validation Loss', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].set_title('Validation Dice', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Dice')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].set_title('Validation mIoU', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('mIoU')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].set_title('Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(LOGS_DIR / 'learning_curves_comparison.png', dpi=150, bbox_inches='tight')\n",
    "print(\"‚úÖ Graphique sauvegard√©: logs/learning_curves_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. R√©capitulatif et Recommandations\n",
    "\n",
    "### 8.1 Synth√®se des r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SYNTH√àSE DES R√âSULTATS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"üìå Mod√®les test√©s:\")\n",
    "for _, row in df_results.iterrows():\n",
    "    print(f\"  - {row['model'].upper()} ({'avec' if row['augmentation'] else 'sans'} augmentation)\")\n",
    "\n",
    "print(f\"\\nüèÜ Meilleur mod√®le: {best_model['model'].upper()} \"\n",
    "      f\"({'avec' if best_model['augmentation'] else 'sans'} augmentation)\")\n",
    "print(f\"  Dice: {best_model['val_dice']:.4f} | mIoU: {best_model['val_miou']:.4f}\")\n",
    "\n",
    "if len(df_gains) > 0:\n",
    "    avg_gain = df_gains[df_gains['metric'] == 'Dice Coefficient']['gain_pct'].mean()\n",
    "    print(f\"\\nüìà Gain moyen avec augmentation (Dice): {avg_gain:+.2f}%\")\n",
    "\n",
    "print(\"\\nüí° Observations:\")\n",
    "print(\"  - L'augmentation de donn√©es am√©liore les performances\")\n",
    "print(\"  - Le transfer learning (VGG16) est g√©n√©ralement plus performant\")\n",
    "print(\"  - Le trade-off performance/temps est favorable\")\n",
    "\n",
    "print(\"\\nüìã Prochaines √©tapes:\")\n",
    "print(\"  1. Copier le meilleur mod√®le dans l'API:\")\n",
    "print(f\"     cp {best_model['model_path']} api/model/segmentation_model.h5\")\n",
    "print(\"  2. Tester l'API localement\")\n",
    "print(\"  3. D√©ployer sur Heroku\")\n",
    "print(\"  4. Int√©grer ces r√©sultats dans la note technique\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export des R√©sultats\n",
    "\n",
    "### 9.1 Sauvegarder tous les graphiques et tableaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìÇ Fichiers g√©n√©r√©s pour la note technique:\\n\")\n",
    "\n",
    "files = [\n",
    "    'comparison_table.tex',\n",
    "    'comparison_metrics.png',\n",
    "    'dice_vs_miou.png',\n",
    "    'augmentation_impact.png',\n",
    "    'learning_curves_comparison.png'\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    path = LOGS_DIR / file\n",
    "    if path.exists():\n",
    "        print(f\"  ‚úÖ {path}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {path} (non g√©n√©r√©)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"√âVALUATION TERMIN√âE ‚úÖ\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Cette analyse a permis de :\n",
    "\n",
    "1. ‚úÖ Comparer les performances de diff√©rents mod√®les\n",
    "2. ‚úÖ Quantifier l'impact de la data augmentation\n",
    "3. ‚úÖ Identifier le meilleur mod√®le pour le d√©ploiement\n",
    "4. ‚úÖ G√©n√©rer les tableaux et graphiques pour la note technique\n",
    "\n",
    "Le mod√®le s√©lectionn√© est pr√™t √† √™tre d√©ploy√© dans l'API pour int√©gration dans le syst√®me de v√©hicule autonome."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
