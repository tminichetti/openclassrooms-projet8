{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation des Donnees et Data Generator\n",
    "\n",
    "Ce notebook prepare les donnees pour l'entrainement du modele de segmentation.\n",
    "\n",
    "## Objectifs\n",
    "- Creer un data generator Keras efficace\n",
    "- Implementer la conversion des 34 classes vers 8 categories\n",
    "- Gerer le redimensionnement des images\n",
    "- Implementer la data augmentation\n",
    "- Preparer les ensembles train/val/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = Path('../data')\n",
    "IMAGES_DIR = DATA_DIR / 'leftImg8bit'\n",
    "LABELS_DIR = DATA_DIR / 'gtFine'\n",
    "\n",
    "# Parametres d'entrainement\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 512\n",
    "N_CLASSES = 8\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "print(f\"Taille des images: {IMG_WIDTH}x{IMG_HEIGHT}\")\n",
    "print(f\"Nombre de classes: {N_CLASSES}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les 8 categories principales\n",
    "CATEGORIES = {\n",
    "    0: {'name': 'void', 'color': (0, 0, 0)},\n",
    "    1: {'name': 'flat', 'color': (128, 64, 128)},\n",
    "    2: {'name': 'construction', 'color': (70, 70, 70)},\n",
    "    3: {'name': 'object', 'color': (153, 153, 153)},\n",
    "    4: {'name': 'nature', 'color': (107, 142, 35)},\n",
    "    5: {'name': 'sky', 'color': (70, 130, 180)},\n",
    "    6: {'name': 'human', 'color': (220, 20, 60)},\n",
    "    7: {'name': 'vehicle', 'color': (0, 0, 142)}\n",
    "}\n",
    "\n",
    "# Mapping des 34 classes originales vers les 8 categories\n",
    "LABEL_TO_CATEGORY = {\n",
    "    0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0,  # void\n",
    "    7: 1, 8: 1, 9: 1, 10: 1,                     # flat\n",
    "    11: 2, 12: 2, 13: 2, 14: 2, 15: 2, 16: 2,   # construction\n",
    "    17: 3, 18: 3, 19: 3, 20: 3,                  # object\n",
    "    21: 4, 22: 4,                                # nature\n",
    "    23: 5,                                       # sky\n",
    "    24: 6, 25: 6,                                # human\n",
    "    26: 7, 27: 7, 28: 7, 29: 7, 30: 7, 31: 7, 32: 7, 33: 7,  # vehicle\n",
    "}\n",
    "\n",
    "# Creer une LUT (Look-Up Table) pour conversion rapide\n",
    "LUT = np.zeros(256, dtype=np.uint8)\n",
    "for label_id, cat_id in LABEL_TO_CATEGORY.items():\n",
    "    LUT[label_id] = cat_id\n",
    "\n",
    "print(\"Look-Up Table creee pour conversion rapide des labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poids de classe (calcules dans le notebook d'exploration)\n",
    "# Ces poids aident a gerer le desequilibre des classes\n",
    "CLASS_WEIGHTS = {\n",
    "    0: 0.1,    # void - poids faible car on l'ignore souvent\n",
    "    1: 0.5,    # flat - tres frequent\n",
    "    2: 0.6,    # construction - frequent\n",
    "    3: 1.0,    # object - moins frequent\n",
    "    4: 0.7,    # nature - assez frequent\n",
    "    5: 0.8,    # sky - moderement frequent\n",
    "    6: 1.0,    # human - rare mais important\n",
    "    7: 1.0,    # vehicle - important pour conduite autonome\n",
    "}\n",
    "\n",
    "# Convertir en array pour Keras\n",
    "class_weights_array = np.array([CLASS_WEIGHTS[i] for i in range(N_CLASSES)])\n",
    "print(\"Poids de classe:\", class_weights_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collecte des chemins de fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_paths(split='train'):\n",
    "    \"\"\"\n",
    "    Collecte tous les chemins images/labels pour un split donne.\n",
    "    \n",
    "    Args:\n",
    "        split: 'train', 'val', ou 'test'\n",
    "        \n",
    "    Returns:\n",
    "        Liste de dictionnaires avec chemins image et label\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    split_dir = IMAGES_DIR / split\n",
    "    \n",
    "    for city_dir in sorted(split_dir.iterdir()):\n",
    "        if not city_dir.is_dir():\n",
    "            continue\n",
    "            \n",
    "        city_name = city_dir.name\n",
    "        \n",
    "        for img_path in sorted(city_dir.glob('*_leftImg8bit.png')):\n",
    "            # Construire le chemin du label\n",
    "            img_name = img_path.stem.replace('_leftImg8bit', '')\n",
    "            label_path = LABELS_DIR / split / city_name / f\"{img_name}_gtFine_labelIds.png\"\n",
    "            \n",
    "            if label_path.exists():\n",
    "                data.append({\n",
    "                    'image': str(img_path),\n",
    "                    'label': str(label_path),\n",
    "                    'city': city_name,\n",
    "                    'name': img_name\n",
    "                })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Collecter les donnees pour chaque split\n",
    "train_data = collect_data_paths('train')\n",
    "val_data = collect_data_paths('val')\n",
    "test_data = collect_data_paths('test')\n",
    "\n",
    "print(f\"Train: {len(train_data)} images\")\n",
    "print(f\"Val: {len(val_data)} images\")\n",
    "print(f\"Test: {len(test_data)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les chemins dans des fichiers CSV pour reference\n",
    "def save_data_paths(data, filename):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(DATA_DIR / filename, index=False)\n",
    "    print(f\"Sauvegarde: {filename}\")\n",
    "\n",
    "save_data_paths(train_data, 'train_paths.csv')\n",
    "save_data_paths(val_data, 'val_paths.csv')\n",
    "save_data_paths(test_data, 'test_paths.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fonctions de preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    \"\"\"\n",
    "    Charge et redimensionne une image.\n",
    "    \n",
    "    Args:\n",
    "        path: Chemin vers l'image\n",
    "        target_size: (height, width)\n",
    "        \n",
    "    Returns:\n",
    "        Image normalisee (0-1) de shape (H, W, 3)\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (target_size[1], target_size[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "def load_label(path, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    \"\"\"\n",
    "    Charge et convertit un mask de labels en 8 categories.\n",
    "    \n",
    "    Args:\n",
    "        path: Chemin vers le mask\n",
    "        target_size: (height, width)\n",
    "        \n",
    "    Returns:\n",
    "        Mask de shape (H, W) avec valeurs 0-7\n",
    "    \"\"\"\n",
    "    # Charger le mask original (valeurs 0-33)\n",
    "    mask = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Redimensionner avec interpolation nearest pour garder les labels discrets\n",
    "    mask = cv2.resize(mask, (target_size[1], target_size[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Convertir vers 8 categories avec la LUT\n",
    "    mask = LUT[mask]\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def mask_to_onehot(mask, n_classes=N_CLASSES):\n",
    "    \"\"\"\n",
    "    Convertit un mask en representation one-hot.\n",
    "    \n",
    "    Args:\n",
    "        mask: Mask de shape (H, W) avec valeurs 0 a n_classes-1\n",
    "        n_classes: Nombre de classes\n",
    "        \n",
    "    Returns:\n",
    "        Mask one-hot de shape (H, W, n_classes)\n",
    "    \"\"\"\n",
    "    return np.eye(n_classes, dtype=np.float32)[mask]\n",
    "\n",
    "# Test des fonctions\n",
    "sample = train_data[0]\n",
    "img = load_image(sample['image'])\n",
    "mask = load_label(sample['label'])\n",
    "\n",
    "print(f\"Image shape: {img.shape}, dtype: {img.dtype}, range: [{img.min():.2f}, {img.max():.2f}]\")\n",
    "print(f\"Mask shape: {mask.shape}, dtype: {mask.dtype}, unique values: {np.unique(mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser un exemple pretraite\n",
    "def visualize_preprocessing(sample):\n",
    "    \"\"\"Visualise l'effet du preprocessing sur une image.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Image originale\n",
    "    img_orig = cv2.imread(sample['image'])\n",
    "    img_orig = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "    axes[0, 0].imshow(img_orig)\n",
    "    axes[0, 0].set_title(f\"Image originale\\n{img_orig.shape}\")\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Mask original\n",
    "    mask_orig = cv2.imread(sample['label'], cv2.IMREAD_GRAYSCALE)\n",
    "    axes[0, 1].imshow(mask_orig, cmap='tab20')\n",
    "    axes[0, 1].set_title(f\"Mask original (34 classes)\\n{mask_orig.shape}\")\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Mask original avec colormap\n",
    "    mask_color_orig = cv2.imread(sample['label'].replace('labelIds', 'color'))\n",
    "    if mask_color_orig is not None:\n",
    "        mask_color_orig = cv2.cvtColor(mask_color_orig, cv2.COLOR_BGR2RGB)\n",
    "        axes[0, 2].imshow(mask_color_orig)\n",
    "    axes[0, 2].set_title(\"Mask colore original\")\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    # Image preprocessee\n",
    "    img = load_image(sample['image'])\n",
    "    axes[1, 0].imshow(img)\n",
    "    axes[1, 0].set_title(f\"Image preprocessee\\n{img.shape}\")\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Mask 8 categories\n",
    "    mask = load_label(sample['label'])\n",
    "    axes[1, 1].imshow(mask, cmap='tab10', vmin=0, vmax=7)\n",
    "    axes[1, 1].set_title(f\"Mask 8 categories\\n{mask.shape}\")\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # Mask colore avec nos categories\n",
    "    mask_colored = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "    for cat_id, info in CATEGORIES.items():\n",
    "        mask_colored[mask == cat_id] = info['color']\n",
    "    axes[1, 2].imshow(mask_colored)\n",
    "    axes[1, 2].set_title(\"Mask 8 categories (colore)\")\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_preprocessing(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation:\n",
    "    \"\"\"\n",
    "    Classe pour appliquer des augmentations coherentes sur image et mask.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 horizontal_flip=True,\n",
    "                 brightness_range=(0.8, 1.2),\n",
    "                 contrast_range=(0.8, 1.2),\n",
    "                 saturation_range=(0.8, 1.2),\n",
    "                 rotation_range=10,\n",
    "                 zoom_range=(0.9, 1.1)):\n",
    "        \n",
    "        self.horizontal_flip = horizontal_flip\n",
    "        self.brightness_range = brightness_range\n",
    "        self.contrast_range = contrast_range\n",
    "        self.saturation_range = saturation_range\n",
    "        self.rotation_range = rotation_range\n",
    "        self.zoom_range = zoom_range\n",
    "    \n",
    "    def __call__(self, image, mask):\n",
    "        \"\"\"\n",
    "        Applique les augmentations.\n",
    "        \n",
    "        Args:\n",
    "            image: Image numpy (H, W, 3) normalisee [0, 1]\n",
    "            mask: Mask numpy (H, W) avec valeurs entieres\n",
    "            \n",
    "        Returns:\n",
    "            image_aug, mask_aug\n",
    "        \"\"\"\n",
    "        # Flip horizontal\n",
    "        if self.horizontal_flip and np.random.random() > 0.5:\n",
    "            image = np.fliplr(image)\n",
    "            mask = np.fliplr(mask)\n",
    "        \n",
    "        # Ajustements de couleur (uniquement sur l'image)\n",
    "        if self.brightness_range:\n",
    "            factor = np.random.uniform(*self.brightness_range)\n",
    "            image = np.clip(image * factor, 0, 1)\n",
    "        \n",
    "        if self.contrast_range:\n",
    "            factor = np.random.uniform(*self.contrast_range)\n",
    "            mean = np.mean(image, axis=(0, 1), keepdims=True)\n",
    "            image = np.clip((image - mean) * factor + mean, 0, 1)\n",
    "        \n",
    "        # Rotation legere\n",
    "        if self.rotation_range:\n",
    "            angle = np.random.uniform(-self.rotation_range, self.rotation_range)\n",
    "            h, w = image.shape[:2]\n",
    "            M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)\n",
    "            image = cv2.warpAffine(image, M, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "            mask = cv2.warpAffine(mask, M, (w, h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_REFLECT)\n",
    "        \n",
    "        return image.astype(np.float32), mask\n",
    "\n",
    "# Test de l'augmentation\n",
    "augmenter = DataAugmentation()\n",
    "print(\"Data augmentation configuree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_augmentation(sample, augmenter, n_examples=4):\n",
    "    \"\"\"Visualise plusieurs augmentations d'une meme image.\"\"\"\n",
    "    img = load_image(sample['image'])\n",
    "    mask = load_label(sample['label'])\n",
    "    \n",
    "    fig, axes = plt.subplots(n_examples, 3, figsize=(12, 4*n_examples))\n",
    "    \n",
    "    for i in range(n_examples):\n",
    "        if i == 0:\n",
    "            img_aug, mask_aug = img.copy(), mask.copy()\n",
    "            title = \"Original\"\n",
    "        else:\n",
    "            img_aug, mask_aug = augmenter(img.copy(), mask.copy())\n",
    "            title = f\"Augmentation {i}\"\n",
    "        \n",
    "        # Image\n",
    "        axes[i, 0].imshow(img_aug)\n",
    "        axes[i, 0].set_title(f\"{title} - Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Mask\n",
    "        axes[i, 1].imshow(mask_aug, cmap='tab10', vmin=0, vmax=7)\n",
    "        axes[i, 1].set_title(f\"{title} - Mask\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        mask_colored = np.zeros((*mask_aug.shape, 3), dtype=np.float32)\n",
    "        for cat_id, info in CATEGORIES.items():\n",
    "            mask_colored[mask_aug == cat_id] = np.array(info['color']) / 255.0\n",
    "        overlay = img_aug * 0.6 + mask_colored * 0.4\n",
    "        axes[i, 2].imshow(overlay)\n",
    "        axes[i, 2].set_title(f\"{title} - Overlay\")\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_augmentation(train_data[10], augmenter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Generator Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityscapesGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Generateur de donnees Keras pour le dataset Cityscapes.\n",
    "    \n",
    "    Herite de Sequence pour le multiprocessing et le shuffling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data,\n",
    "                 batch_size=8,\n",
    "                 target_size=(256, 512),\n",
    "                 n_classes=8,\n",
    "                 augmentation=None,\n",
    "                 shuffle=True,\n",
    "                 one_hot=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: Liste de dicts avec 'image' et 'label' paths\n",
    "            batch_size: Taille des batches\n",
    "            target_size: (height, width) des images de sortie\n",
    "            n_classes: Nombre de classes\n",
    "            augmentation: Instance de DataAugmentation ou None\n",
    "            shuffle: Melanger les donnees a chaque epoque\n",
    "            one_hot: Retourner les masks en one-hot encoding\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.n_classes = n_classes\n",
    "        self.augmentation = augmentation\n",
    "        self.shuffle = shuffle\n",
    "        self.one_hot = one_hot\n",
    "        self.indexes = np.arange(len(self.data))\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Nombre de batches par epoque.\"\"\"\n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Genere un batch de donnees.\"\"\"\n",
    "        # Indices pour ce batch\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        # Charger les donnees\n",
    "        batch_images = []\n",
    "        batch_masks = []\n",
    "        \n",
    "        for idx in batch_indexes:\n",
    "            sample = self.data[idx]\n",
    "            \n",
    "            # Charger image et mask\n",
    "            image = load_image(sample['image'], self.target_size)\n",
    "            mask = load_label(sample['label'], self.target_size)\n",
    "            \n",
    "            # Appliquer l'augmentation\n",
    "            if self.augmentation:\n",
    "                image, mask = self.augmentation(image, mask)\n",
    "            \n",
    "            batch_images.append(image)\n",
    "            batch_masks.append(mask)\n",
    "        \n",
    "        # Convertir en arrays\n",
    "        X = np.array(batch_images, dtype=np.float32)\n",
    "        \n",
    "        if self.one_hot:\n",
    "            y = np.array([mask_to_onehot(m, self.n_classes) for m in batch_masks], dtype=np.float32)\n",
    "        else:\n",
    "            y = np.array(batch_masks, dtype=np.int32)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Appele a la fin de chaque epoque.\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def get_sample(self, index):\n",
    "        \"\"\"Recupere un echantillon specifique (pour visualisation).\"\"\"\n",
    "        sample = self.data[index]\n",
    "        image = load_image(sample['image'], self.target_size)\n",
    "        mask = load_label(sample['label'], self.target_size)\n",
    "        return image, mask, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer les generateurs\n",
    "train_augmentation = DataAugmentation(\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.8, 1.2),\n",
    "    contrast_range=(0.9, 1.1),\n",
    "    rotation_range=5\n",
    ")\n",
    "\n",
    "train_generator = CityscapesGenerator(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    augmentation=train_augmentation,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = CityscapesGenerator(\n",
    "    val_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    augmentation=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = CityscapesGenerator(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    augmentation=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Train generator: {len(train_generator)} batches\")\n",
    "print(f\"Val generator: {len(val_generator)} batches\")\n",
    "print(f\"Test generator: {len(test_generator)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du generateur\n",
    "X_batch, y_batch = train_generator[0]\n",
    "\n",
    "print(f\"Batch X shape: {X_batch.shape}\")\n",
    "print(f\"Batch y shape: {y_batch.shape}\")\n",
    "print(f\"X dtype: {X_batch.dtype}, range: [{X_batch.min():.3f}, {X_batch.max():.3f}]\")\n",
    "print(f\"y dtype: {y_batch.dtype}, range: [{y_batch.min():.3f}, {y_batch.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(generator, batch_idx=0):\n",
    "    \"\"\"Visualise un batch de donnees.\"\"\"\n",
    "    X, y = generator[batch_idx]\n",
    "    n_samples = min(4, len(X))\n",
    "    \n",
    "    fig, axes = plt.subplots(n_samples, 3, figsize=(12, 4*n_samples))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Image\n",
    "        axes[i, 0].imshow(X[i])\n",
    "        axes[i, 0].set_title(f\"Image {i}\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Mask (argmax du one-hot)\n",
    "        mask = np.argmax(y[i], axis=-1)\n",
    "        axes[i, 1].imshow(mask, cmap='tab10', vmin=0, vmax=7)\n",
    "        axes[i, 1].set_title(f\"Mask {i}\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        mask_colored = np.zeros((*mask.shape, 3), dtype=np.float32)\n",
    "        for cat_id, info in CATEGORIES.items():\n",
    "            mask_colored[mask == cat_id] = np.array(info['color']) / 255.0\n",
    "        overlay = X[i] * 0.6 + mask_colored * 0.4\n",
    "        axes[i, 2].imshow(overlay)\n",
    "        axes[i, 2].set_title(f\"Overlay {i}\")\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_batch(train_generator, batch_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. tf.data Pipeline (Alternative plus performante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(data, batch_size, target_size, augment=False, shuffle=True):\n",
    "    \"\"\"\n",
    "    Cree un tf.data.Dataset pour des performances optimales.\n",
    "    \n",
    "    Args:\n",
    "        data: Liste de dicts avec 'image' et 'label' paths\n",
    "        batch_size: Taille des batches\n",
    "        target_size: (height, width)\n",
    "        augment: Appliquer l'augmentation\n",
    "        shuffle: Melanger les donnees\n",
    "    \n",
    "    Returns:\n",
    "        tf.data.Dataset\n",
    "    \"\"\"\n",
    "    image_paths = [d['image'] for d in data]\n",
    "    label_paths = [d['label'] for d in data]\n",
    "    \n",
    "    def load_and_preprocess(img_path, label_path):\n",
    "        # Charger l'image\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_png(img, channels=3)\n",
    "        img = tf.image.resize(img, target_size)\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        \n",
    "        # Charger le mask\n",
    "        mask = tf.io.read_file(label_path)\n",
    "        mask = tf.image.decode_png(mask, channels=1)\n",
    "        mask = tf.image.resize(mask, target_size, method='nearest')\n",
    "        mask = tf.squeeze(mask, axis=-1)\n",
    "        \n",
    "        # Convertir vers 8 categories avec tf.gather\n",
    "        lut_tensor = tf.constant(LUT, dtype=tf.int32)\n",
    "        mask = tf.cast(mask, tf.int32)\n",
    "        mask = tf.gather(lut_tensor, mask)\n",
    "        \n",
    "        # One-hot encoding\n",
    "        mask = tf.one_hot(mask, N_CLASSES)\n",
    "        \n",
    "        return img, mask\n",
    "    \n",
    "    def augment_fn(img, mask):\n",
    "        # Flip horizontal\n",
    "        if tf.random.uniform([]) > 0.5:\n",
    "            img = tf.image.flip_left_right(img)\n",
    "            mask = tf.image.flip_left_right(mask)\n",
    "        \n",
    "        # Brightness\n",
    "        img = tf.image.random_brightness(img, 0.2)\n",
    "        img = tf.clip_by_value(img, 0, 1)\n",
    "        \n",
    "        # Contrast\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        img = tf.clip_by_value(img, 0, 1)\n",
    "        \n",
    "        return img, mask\n",
    "    \n",
    "    # Creer le dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, label_paths))\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(data))\n",
    "    \n",
    "    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if augment:\n",
    "        dataset = dataset.map(augment_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Creer les datasets tf.data\n",
    "train_dataset = create_tf_dataset(train_data, BATCH_SIZE, (IMG_HEIGHT, IMG_WIDTH), augment=True, shuffle=True)\n",
    "val_dataset = create_tf_dataset(val_data, BATCH_SIZE, (IMG_HEIGHT, IMG_WIDTH), augment=False, shuffle=False)\n",
    "\n",
    "print(\"tf.data Datasets crees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du tf.data pipeline\n",
    "for X, y in train_dataset.take(1):\n",
    "    print(f\"tf.data batch X shape: {X.shape}\")\n",
    "    print(f\"tf.data batch y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde de la configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder la configuration complete\n",
    "config = {\n",
    "    'img_height': IMG_HEIGHT,\n",
    "    'img_width': IMG_WIDTH,\n",
    "    'n_classes': N_CLASSES,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'categories': {str(k): v['name'] for k, v in CATEGORIES.items()},\n",
    "    'class_weights': CLASS_WEIGHTS,\n",
    "    'n_train': len(train_data),\n",
    "    'n_val': len(val_data),\n",
    "    'n_test': len(test_data)\n",
    "}\n",
    "\n",
    "with open(DATA_DIR / 'config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"Configuration sauvegardee dans data/config.json\")\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resume et Export des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les fonctions utilitaires dans un module Python\n",
    "utils_code = '''\n",
    "\"\"\"Utilitaires pour le projet de segmentation Cityscapes.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 512\n",
    "N_CLASSES = 8\n",
    "\n",
    "CATEGORIES = {\n",
    "    0: {\\'name\\': \\'void\\', \\'color\\': (0, 0, 0)},\n",
    "    1: {\\'name\\': \\'flat\\', \\'color\\': (128, 64, 128)},\n",
    "    2: {\\'name\\': \\'construction\\', \\'color\\': (70, 70, 70)},\n",
    "    3: {\\'name\\': \\'object\\', \\'color\\': (153, 153, 153)},\n",
    "    4: {\\'name\\': \\'nature\\', \\'color\\': (107, 142, 35)},\n",
    "    5: {\\'name\\': \\'sky\\', \\'color\\': (70, 130, 180)},\n",
    "    6: {\\'name\\': \\'human\\', \\'color\\': (220, 20, 60)},\n",
    "    7: {\\'name\\': \\'vehicle\\', \\'color\\': (0, 0, 142)}\n",
    "}\n",
    "\n",
    "LABEL_TO_CATEGORY = {\n",
    "    0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0,\n",
    "    7: 1, 8: 1, 9: 1, 10: 1,\n",
    "    11: 2, 12: 2, 13: 2, 14: 2, 15: 2, 16: 2,\n",
    "    17: 3, 18: 3, 19: 3, 20: 3,\n",
    "    21: 4, 22: 4,\n",
    "    23: 5,\n",
    "    24: 6, 25: 6,\n",
    "    26: 7, 27: 7, 28: 7, 29: 7, 30: 7, 31: 7, 32: 7, 33: 7,\n",
    "}\n",
    "\n",
    "# LUT pour conversion rapide\n",
    "LUT = np.zeros(256, dtype=np.uint8)\n",
    "for label_id, cat_id in LABEL_TO_CATEGORY.items():\n",
    "    LUT[label_id] = cat_id\n",
    "\n",
    "\n",
    "def load_image(path, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    \"\"\"Charge et preprocesse une image.\"\"\"\n",
    "    img = cv2.imread(str(path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (target_size[1], target_size[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_label(path, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    \"\"\"Charge et convertit un mask en 8 categories.\"\"\"\n",
    "    mask = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (target_size[1], target_size[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    mask = LUT[mask]\n",
    "    return mask\n",
    "\n",
    "\n",
    "def mask_to_onehot(mask, n_classes=N_CLASSES):\n",
    "    \"\"\"Convertit un mask en one-hot.\"\"\"\n",
    "    return np.eye(n_classes, dtype=np.float32)[mask]\n",
    "\n",
    "\n",
    "def mask_to_rgb(mask):\n",
    "    \"\"\"Convertit un mask en image RGB coloree.\"\"\"\n",
    "    rgb = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "    for cat_id, info in CATEGORIES.items():\n",
    "        rgb[mask == cat_id] = info[\\'color\\']\n",
    "    return rgb\n",
    "'''\n",
    "\n",
    "# Creer le dossier src s'il n'existe pas\n",
    "src_dir = Path('../src')\n",
    "src_dir.mkdir(exist_ok=True)\n",
    "\n",
    "with open(src_dir / 'utils.py', 'w') as f:\n",
    "    f.write(utils_code)\n",
    "\n",
    "print(\"Module utils.py sauvegarde dans src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUME - PREPARATION DES DONNEES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nImages: {IMG_WIDTH}x{IMG_HEIGHT} pixels\")\n",
    "print(f\"Classes: {N_CLASSES} categories\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"\\nDatasets:\")\n",
    "print(f\"  - Train: {len(train_data)} images ({len(train_generator)} batches)\")\n",
    "print(f\"  - Val: {len(val_data)} images ({len(val_generator)} batches)\")\n",
    "print(f\"  - Test: {len(test_data)} images ({len(test_generator)} batches)\")\n",
    "print(f\"\\nFichiers crees:\")\n",
    "print(f\"  - data/train_paths.csv\")\n",
    "print(f\"  - data/val_paths.csv\")\n",
    "print(f\"  - data/test_paths.csv\")\n",
    "print(f\"  - data/config.json\")\n",
    "print(f\"  - src/utils.py\")\n",
    "print(f\"\\nData augmentation:\")\n",
    "print(f\"  - Flip horizontal\")\n",
    "print(f\"  - Brightness jittering\")\n",
    "print(f\"  - Contrast jittering\")\n",
    "print(f\"  - Rotation legere\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prochaines etapes\n",
    "\n",
    "1. **Notebook 03**: Architecture du modele (U-Net avec backbone)\n",
    "2. **Notebook 04**: Entrainement et callbacks\n",
    "3. **Notebook 05**: Evaluation et metriques (IoU, Dice)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
