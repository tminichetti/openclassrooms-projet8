# Guide d'EntraÃ®nement des ModÃ¨les

Ce guide explique comment entraÃ®ner les modÃ¨les de segmentation et comparer les rÃ©sultats.

## ğŸ“‹ PrÃ©requis

1. **DonnÃ©es prÃ©parÃ©es** :
   - `data/train_paths.csv`
   - `data/val_paths.csv`
   - `data/config.json`

2. **DÃ©pendances installÃ©es** :
   ```bash
   pip install -r requirements.txt
   ```

3. **GPU recommandÃ©** (mais fonctionne sur CPU)

---

## ğŸš€ EntraÃ®nement des ModÃ¨les

### Option 1 : Script Python (RecommandÃ©)

Le script `train.py` permet d'entraÃ®ner les modÃ¨les facilement depuis la ligne de commande.

#### EntraÃ®ner U-Net simple SANS augmentation
```bash
python train.py --model unet --no-augmentation --epochs 30
```

#### EntraÃ®ner U-Net simple AVEC augmentation
```bash
python train.py --model unet --augmentation --epochs 30
```

#### EntraÃ®ner VGG16 SANS augmentation
```bash
python train.py --model vgg16 --no-augmentation --epochs 30
```

#### EntraÃ®ner VGG16 AVEC augmentation
```bash
python train.py --model vgg16 --augmentation --epochs 30
```

#### Options disponibles
```bash
python train.py --help

Options:
  --model {unet,vgg16}     Type de modÃ¨le
  --augmentation           Activer data augmentation
  --no-augmentation        DÃ©sactiver data augmentation
  --epochs N               Nombre d'epochs (dÃ©faut: 30)
  --batch-size N           Taille des batches (dÃ©faut: 8)
  --learning-rate LR       Learning rate (dÃ©faut: 0.0001)
  --patience N             Patience early stopping (dÃ©faut: 10)
```

### Option 2 : Notebook Jupyter

Si vous prÃ©fÃ©rez utiliser les notebooks :

```bash
jupyter notebook notebooks/04_training.ipynb
```

Puis exÃ©cuter toutes les cellules.

---

## ğŸ“Š Comparaison des RÃ©sultats

AprÃ¨s avoir entraÃ®nÃ© **au moins 2 modÃ¨les**, comparer les rÃ©sultats.

### Option 1 : Notebook Jupyter (RecommandÃ© â­)

```bash
jupyter notebook notebooks/05_evaluation.ipynb
```

Puis exÃ©cuter toutes les cellules. Le notebook va :
- âœ… Afficher un tableau comparatif interactif
- âœ… Analyser l'impact de l'augmentation
- âœ… Identifier le meilleur modÃ¨le
- âœ… GÃ©nÃ©rer 5 graphiques professionnels
- âœ… Exporter les tableaux (LaTeX pour note technique)
- âœ… Analyser les courbes d'apprentissage

**Avantage** : Visualisations interactives + documentation intÃ©grÃ©e, parfait pour la note technique !

### Option 2 : Script Python (vÃ©rification rapide)

```bash
python compare_models.py
```

**Avantage** : Plus rapide pour un check en ligne de commande

### Fichiers gÃ©nÃ©rÃ©s

```
logs/
â”œâ”€â”€ all_results.csv           # Tous les rÃ©sultats d'entraÃ®nement
â”œâ”€â”€ comparison.png            # Graphiques comparatifs
â”œâ”€â”€ comparison_table.md       # Tableau Markdown (pour GitHub)
â””â”€â”€ comparison_table.tex      # Tableau LaTeX (pour note technique)
```

---

## ğŸ¯ Plan d'EntraÃ®nement RecommandÃ©

Pour satisfaire **Milestone 3**, voici le plan minimal :

### Phase 1 : Tests rapides (2-3 epochs) âš¡
VÃ©rifier que tout fonctionne :
```bash
python train.py --model unet --no-augmentation --epochs 3
python train.py --model unet --augmentation --epochs 3
```

### Phase 2 : EntraÃ®nements complets ğŸš€

**Configuration minimale (CPU/GPU faible)** :
```bash
# U-Net sans augmentation (baseline)
python train.py --model unet --no-augmentation --epochs 20 --batch-size 4

# U-Net avec augmentation
python train.py --model unet --augmentation --epochs 20 --batch-size 4

# VGG16 avec augmentation (meilleur modÃ¨le attendu)
python train.py --model vgg16 --augmentation --epochs 20 --batch-size 4
```

**Configuration optimale (GPU performant)** :
```bash
# U-Net sans augmentation
python train.py --model unet --no-augmentation --epochs 50 --batch-size 8

# U-Net avec augmentation
python train.py --model unet --augmentation --epochs 50 --batch-size 8

# VGG16 sans augmentation
python train.py --model vgg16 --no-augmentation --epochs 40 --batch-size 8

# VGG16 avec augmentation
python train.py --model vgg16 --augmentation --epochs 40 --batch-size 8
```

### Phase 3 : Analyse des rÃ©sultats ğŸ“ˆ
```bash
python compare_models.py
```

---

## ğŸ“‚ Organisation des Fichiers

AprÃ¨s l'entraÃ®nement, voici l'organisation :

```
.
â”œâ”€â”€ train.py                          # Script d'entraÃ®nement
â”œâ”€â”€ compare_models.py                 # Script de comparaison
â”œâ”€â”€ models/                           # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ unet_no-aug_YYYYMMDD_HHMMSS_best.keras
â”‚   â”œâ”€â”€ unet_aug_YYYYMMDD_HHMMSS_best.keras
â”‚   â”œâ”€â”€ vgg16_no-aug_YYYYMMDD_HHMMSS_best.keras
â”‚   â””â”€â”€ vgg16_aug_YYYYMMDD_HHMMSS_best.keras
â””â”€â”€ logs/                             # Logs d'entraÃ®nement
    â”œâ”€â”€ all_results.csv               # RÃ©sultats consolidÃ©s
    â”œâ”€â”€ comparison.png                # Graphiques
    â”œâ”€â”€ comparison_table.md           # Tableau Markdown
    â”œâ”€â”€ unet_no-aug_YYYYMMDD_HHMMSS/
    â”‚   â”œâ”€â”€ config.json               # Config expÃ©rience
    â”‚   â”œâ”€â”€ training_log.csv          # Log par epoch
    â”‚   â”œâ”€â”€ history.csv               # Historique complet
    â”‚   â”œâ”€â”€ training_curves.png       # Courbes d'apprentissage
    â”‚   â””â”€â”€ results.json              # RÃ©sultats finaux
    â”œâ”€â”€ unet_aug_YYYYMMDD_HHMMSS/
    â”œâ”€â”€ vgg16_no-aug_YYYYMMDD_HHMMSS/
    â””â”€â”€ vgg16_aug_YYYYMMDD_HHMMSS/
```

---

## â±ï¸ Temps d'EntraÃ®nement EstimÃ©s

### Sur CPU (macOS M1/M2 ou Ã©quivalent)
- U-Net (30 epochs) : **~2-3 heures**
- VGG16 (30 epochs) : **~3-4 heures**

### Sur GPU (NVIDIA RTX 3060 ou Ã©quivalent)
- U-Net (30 epochs) : **~20-30 minutes**
- VGG16 (30 epochs) : **~30-45 minutes**

### Sur Google Colab (GPU gratuit)
- U-Net (30 epochs) : **~30-40 minutes**
- VGG16 (30 epochs) : **~45-60 minutes**

---

## ğŸ“ Utiliser Google Colab (GPU gratuit)

Si vous n'avez pas de GPU local :

### 1. CrÃ©er un notebook Colab

Aller sur : https://colab.research.google.com/

### 2. Activer GPU

Runtime â†’ Change runtime type â†’ GPU

### 3. Installer les dÃ©pendances

```python
!git clone https://github.com/votre-username/openclassrooms-projet8.git
%cd openclassrooms-projet8
!pip install -r requirements.txt
```

### 4. Uploader les donnÃ©es

Soit via Google Drive, soit via :
```python
from google.colab import files
# Upload data/config.json, data/train_paths.csv, data/val_paths.csv
```

### 5. Lancer l'entraÃ®nement

```python
!python train.py --model unet --augmentation --epochs 30
```

### 6. TÃ©lÃ©charger les rÃ©sultats

```python
from google.colab import files
files.download('models/unet_aug_YYYYMMDD_HHMMSS_best.keras')
files.download('logs/all_results.csv')
```

---

## ğŸ› DÃ©pannage

### Erreur : Out of Memory (OOM)

**Solution 1** : RÃ©duire batch size
```bash
python train.py --model unet --augmentation --batch-size 4
```

**Solution 2** : RÃ©duire taille des images
Ã‰diter `data/config.json` :
```json
{
  "img_height": 128,
  "img_width": 256
}
```

### Erreur : Module not found

Installer les dÃ©pendances :
```bash
pip install tensorflow pandas numpy opencv-python matplotlib
```

### L'entraÃ®nement est trop lent sur CPU

Options :
1. Utiliser Google Colab (GPU gratuit)
2. RÃ©duire le nombre d'epochs
3. RÃ©duire le nombre de donnÃ©es d'entraÃ®nement (pour tests)

### Callbacks ne s'arrÃªtent pas

VÃ©rifier la patience :
```bash
python train.py --model unet --augmentation --patience 5
```

---

## ğŸ“ˆ MÃ©triques Ã  Surveiller

### Pendant l'entraÃ®nement

1. **Loss** (doit diminuer) :
   - Train loss < Val loss = normal
   - Ã‰cart trop grand = overfitting

2. **Dice Coefficient** (doit augmenter) :
   - > 0.70 = bon modÃ¨le
   - > 0.80 = trÃ¨s bon modÃ¨le

3. **Mean IoU** (doit augmenter) :
   - > 0.60 = bon modÃ¨le
   - > 0.70 = trÃ¨s bon modÃ¨le

4. **Accuracy** (doit augmenter) :
   - > 0.85 = bon modÃ¨le
   - > 0.90 = trÃ¨s bon modÃ¨le

### AprÃ¨s l'entraÃ®nement

Comparer :
- **Impact augmentation** : gain attendu de 2-5% sur Dice
- **Transfer learning** : VGG16 devrait Ãªtre meilleur que U-Net simple
- **Temps d'entraÃ®nement** : Trade-off performance/temps

---

## âœ… Checklist Milestone 3

Avant de passer Ã  la suite, vÃ©rifier :

- [ ] Au moins **2 modÃ¨les** entraÃ®nÃ©s (U-Net + VGG16 recommandÃ©)
- [ ] Comparaison **avec/sans augmentation** (minimum 1 modÃ¨le)
- [ ] **Tableau comparatif** gÃ©nÃ©rÃ© (`logs/comparison_table.md`)
- [ ] **Graphiques** gÃ©nÃ©rÃ©s (`logs/comparison.png`)
- [ ] **Meilleur modÃ¨le** identifiÃ©
- [ ] **EarlyStopping** et **ModelCheckpoint** utilisÃ©s (automatique dans le script)
- [ ] **Gains augmentation** documentÃ©s
- [ ] **Temps d'entraÃ®nement** documentÃ©s

---

## ğŸš€ Prochaines Ã‰tapes (Milestone 6)

AprÃ¨s l'entraÃ®nement :

1. **Copier le meilleur modÃ¨le** dans l'API :
   ```bash
   cp models/MEILLEUR_MODELE.keras api/model/segmentation_model.h5
   ```

2. **Tester l'API** localement :
   ```bash
   cd api
   python app.py
   python test_api.py
   ```

3. **DÃ©ployer sur Heroku** :
   ```bash
   cd api
   heroku create nom-api
   git push heroku main
   ```

4. **DÃ©ployer Streamlit** :
   - Push sur GitHub
   - DÃ©ployer sur Streamlit Cloud
   - Configurer API_URL

5. **RÃ©diger note technique** avec :
   - Tableau comparatif
   - Graphiques
   - Analyse des rÃ©sultats
   - Recommandations

---

## ğŸ“ Support

Si vous rencontrez des problÃ¨mes :

1. VÃ©rifier les logs dans `logs/`
2. VÃ©rifier les fichiers de config
3. Consulter le fichier ANALYSE_NOTEBOOKS.md
4. Consulter le fichier MILESTONES.md

Bon courage ! ğŸ“ğŸš€
